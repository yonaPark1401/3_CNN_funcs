{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2GPoeVHUVTq"
   },
   "source": [
    "# Практическое задание 3\n",
    "\n",
    "## Замечания\n",
    "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
    "* Ничего, крому Numpy, нельзя использовать для реализации \n",
    "* **Keras** используется только для тестирования Вашей реализации\n",
    "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
    "* Возможно использование дополнительных (приватных) тестов\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hT1dNA7Gb35a"
   },
   "outputs": [],
   "source": [
    "# Вам понадобится для реализации\n",
    "import numpy as np\n",
    "# Нужно для тестирования\n",
    "from tensorflow import keras\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G7sQn2ZXh9Y"
   },
   "source": [
    "* Вспомогательные функции для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_vXhfmihINmY"
   },
   "outputs": [],
   "source": [
    "def compare_tensors(x, y, tol=0.001, test_name='Test'):\n",
    "  assert (x.shape == y.shape), test_name + ' different shapes'\n",
    "  diff = np.sum((y - x)**2)\n",
    "  assert (diff < tol), test_name + ' Failed!'\n",
    "  print (test_name + ' Passed!')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Pq_lVMUle_ii"
   },
   "outputs": [],
   "source": [
    "def compare_tensors_array(x, y, tol=0.001, test_name='Test'):\n",
    "  assert (len(x) == len(y)), test_name + ' different lengths'\n",
    "  for i in range(len(x)):\n",
    "    t = test_name + ' subtest ' + str(i)\n",
    "    compare_tensors(x[i], y[i], tol=tol, test_name=t)\n",
    "  print (test_name + ' Passed!')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4iNYGlDyNAF"
   },
   "source": [
    "* Шаблон класса любой операции (слоя), которую Вам необходимо будет реализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "05lYhmjMSm0s"
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'Layer'       \n",
    "    def forward(self, input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caE-Xn1ZY79p"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9yuQiPjyOBZ"
   },
   "source": [
    "* (1 балл) Реализация \"спрямляющего\" слоя Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zJIqDFDC-8Gh"
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    def __init__(self):\n",
    "      self.name = 'Flatten'\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Преобразуем в двухмерный тензор: при этом по первой размерности НЕ преобразуем\n",
    "      # Выкладываем данные: сначала по последней размерности, затем по предпоследней и т.д.\n",
    "      # Нужно заполнить Nu mpy-тензор out  \n",
    "      in_shape = np.array(input_data).shape\n",
    "      out = []\n",
    "        \n",
    "      for batch in range(in_shape[0]):\n",
    "          raws = []\n",
    "          new_raw = []\n",
    "          \n",
    "          for raw_idx in range(in_shape[2]):\n",
    "              raws = [input_data[batch][channel][raw_idx] for channel in range(in_shape[1])]\n",
    "              raws = np.stack(raws, axis=1)\n",
    "              raws = np.concatenate(raws)\n",
    "              new_raw.append(raws)\n",
    "                \n",
    "          new_raw = np.array(new_raw).reshape(-1)\n",
    "          out.append(new_raw)\n",
    "            \n",
    "      out = np.array(out) \n",
    "      # out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAD92fJkYcNI"
   },
   "source": [
    "* Функция предварительного тестирования слоя **Flatten**\n",
    "* Функции с названием \"**test_**\" не менять\n",
    "* Вы можете самостоятельно поиграться с параметрами типа B/C/H/W etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eZsoCXd1HioL"
   },
   "outputs": [],
   "source": [
    "def test_FlattenLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Flatten(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = FlattenLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 1')\n",
    "  B = 1\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Flatten(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = FlattenLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMe7eba6Yu4a"
   },
   "source": [
    "* Запуск теста слоя Flatten\n",
    "* Нужно, чтобы все тесты были '*Passed!*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pST9EihGKTEh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Flatten 1 Passed!\n",
      "Test Flatten 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_FlattenLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOngWlbqyQJ9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NfaNFKZGOk"
   },
   "source": [
    "* (1 балл) Реализация слоя субдискретизации **Global Average Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1d3U8gE1-8J1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12924\\3375437260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mGAP2DLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'GAP2D'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "class GAP2DLayer(Layer):\n",
    "    def __init__(self):\n",
    "      self.name = 'GAP2D'\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Сворачиваем по двум последним размерностям (то есть на выходе - минус две размерности)\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "        shape = input_data.shape\n",
    "        out = []\n",
    "        for batch in range(shape[0]):\n",
    "            channel_arr = []\n",
    "\n",
    "            for channel in range(shape[1]):\n",
    "                w_sum = np.array([np.sum(arr) for arr in input_data[batch][channel]])\n",
    "                w_divider = shape[3]\n",
    "                w_result = w_sum / w_divider\n",
    "\n",
    "                val_divider = shape[2]\n",
    "                final_val = np.sum(w_result) / val_divider\n",
    "                channel_arr.append(final_val)\n",
    "\n",
    "            out.append(channel_arr)\n",
    " \n",
    "        out = np.array(out)\n",
    "        # out = np.empty([])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u9KLCdrTLT-j"
   },
   "outputs": [],
   "source": [
    "def test_GAP2DLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = GAP2DLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 1')\n",
    "  B = 1\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = GAP2DLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AbuDxhloPLKs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test GAP2D 1 Passed!\n",
      "Test GAP2D 2 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_GAP2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbse3gb2ySI_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2CCmuiZZTXp"
   },
   "source": [
    "* (2 балла) Реализация слоя субдискретизации **MaxPooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fFSW6Xpp-8NS"
   },
   "outputs": [],
   "source": [
    "class MaxPool2DLayer(Layer):\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "      self.name = 'MaxPool2D'\n",
    "      self.pool_size = pool_size\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      # out = np.empty([])\n",
    "      shape = input_data.shape\n",
    "      out = []\n",
    "      for batch in range(shape[0]):\n",
    "          batch_arr = []\n",
    "          for channel in range(shape[1]):\n",
    "              channel_arr = []\n",
    "              vals = []\n",
    "              for raw in range(0, shape[2], self.stride):\n",
    "                  if raw + self.pool_size > shape[2]:\n",
    "                      break\n",
    "                  pooled_data = [np.max(input_data[batch][channel][raw:raw+self.pool_size, col:col+self.pool_size])\n",
    "                                        for col in range(0, shape[3], self.stride)\n",
    "                                        if col + self.pool_size <= shape[3]]\n",
    "                  channel_arr.append(pooled_data)\n",
    "              channel_arr = np.array(channel_arr).reshape(-1)\n",
    "              channel_arr = np.expand_dims(channel_arr, axis=1)\n",
    "              batch_arr.append(channel_arr)\n",
    "          out.append(batch_arr)\n",
    "      out = np.array(out)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kvCIn_aXUPkD"
   },
   "outputs": [],
   "source": [
    "def test_MaxPool2DLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 4\n",
    "  W = 4\n",
    "  pool_size = 2\n",
    "  stride = 2\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "#   y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
    "#   y_keras = y(x).numpy()\n",
    "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "#   compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 1')\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  pool_size = 2\n",
    "  stride = 1  \n",
    "  x = np.random.randn(B, C, H, W)\n",
    "#   y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
    "#   y_keras = y(x).numpy()\n",
    "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "#   compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GHRtvEIpVsYe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1.19373037 -0.47563104 -1.80720975]\n",
      "   [-0.97288308 -0.36535866  1.0487244 ]\n",
      "   [-0.89148072 -1.88005553  2.04017067]]\n",
      "\n",
      "  [[-2.19326417  1.00409025  0.6323169 ]\n",
      "   [-0.76396745  0.67916278  0.4903245 ]\n",
      "   [-0.87940529 -0.13046821 -0.43074683]]]\n",
      "\n",
      "\n",
      " [[[ 1.5291461   0.85049268  1.33586984]\n",
      "   [-1.36521824  0.24638333 -1.9505574 ]\n",
      "   [ 0.57913739  0.66941551 -0.08326311]]\n",
      "\n",
      "  [[ 0.41793839  0.16968227 -0.94651394]\n",
      "   [-0.04385755 -1.69168188 -0.88913239]\n",
      "   [ 0.41828686 -0.13152112  2.64323824]]]]\n",
      "[[[[ 1.19373037]\n",
      "   [ 1.0487244 ]\n",
      "   [-0.36535866]\n",
      "   [ 2.04017067]]\n",
      "\n",
      "  [[ 1.00409025]\n",
      "   [ 1.00409025]\n",
      "   [ 0.67916278]\n",
      "   [ 0.67916278]]]\n",
      "\n",
      "\n",
      " [[[ 1.5291461 ]\n",
      "   [ 1.33586984]\n",
      "   [ 0.66941551]\n",
      "   [ 0.66941551]]\n",
      "\n",
      "  [[ 0.41793839]\n",
      "   [ 0.16968227]\n",
      "   [ 0.41828686]\n",
      "   [ 2.64323824]]]]\n"
     ]
    }
   ],
   "source": [
    "test_MaxPool2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLtOD86byTQ-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zruUuHDeZf-4"
   },
   "source": [
    "* (3 балла) Реализация слоя **активации** (поддерживаются **relu**, **sigmoid**, **softmax**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yFytq6FOByQ9"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation='relu'):\n",
    "      # Активация (поддерживаем 'relu', 'sigmoid', 'softmax')\n",
    "      self.name = 'Activation'\n",
    "      self.activation = activation\n",
    "    \n",
    "    def forward(self, input_data):   \n",
    "      # На входе:\n",
    "      # четырехмерный тензор вида [batch, input_channels, height, width] для 'relu', 'sigmoid'\n",
    "      # или двухмерный тензор вида [batch, logits]\n",
    "      # SoftMax применяется по последней размерности\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      # out = np.empty([])\n",
    "          \n",
    "      shape = input_data.shape\n",
    "      out = []\n",
    "        \n",
    "      if self.activation != 'softmax':\n",
    "          func_dict = {\n",
    "              'relu': lambda x: x if x>0 else 0,\n",
    "              'sigmoid': lambda x: 1/(1+math.e**(-x)),\n",
    "          }\n",
    "\n",
    "          for batch in range(shape[0]):\n",
    "              batch_arr = []\n",
    "              for channel in range(shape[1]):\n",
    "                  channel_arr = []\n",
    "                  divider = 0\n",
    "                  for raw in range(shape[2]):\n",
    "                      activated = [func_dict[self.activation](input_data[batch, channel, raw, col]) for col in range(shape[3])]\n",
    "                      channel_arr.append(activated)\n",
    "                  batch_arr.append(channel_arr)  \n",
    "              out.append(batch_arr)\n",
    "      else:\n",
    "        for batch in range(shape[0]):\n",
    "            exponents = np.exp(input_data[batch])\n",
    "            divider = sum(exponents)\n",
    "            out.append(exponents/divider)\n",
    "      out = np.array(out)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-RnOBuLTWcIf"
   },
   "outputs": [],
   "source": [
    "def test_ActivationLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 4\n",
    "  W = 4\n",
    "  activation = 'relu'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 1')\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  activation = 'sigmoid'  \n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 2')\n",
    "  B = 3\n",
    "  C = 10\n",
    "  activation = 'softmax'\n",
    "  x = np.random.randn(B, C)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 3')  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "n3Bwcpw7X4_m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Activation 1 Passed!\n",
      "Test Activation 2 Passed!\n",
      "Test Activation 3 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_ActivationLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YtW9jiayUdV"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dOJl776Z0t7"
   },
   "source": [
    "* (3 балла) Реализация слоя пакетной нормализации **BatchNorm** (как для режима train, так и для режима test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0-bCGIE--8QH"
   },
   "outputs": [],
   "source": [
    "# Hint\n",
    "# Train mode:\n",
    "# out = (batch - mean(batch)) / sqrt(var(batch) + epsilon) * gamma + beta\n",
    "# moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\n",
    "# moving_var = moving_var * momentum + var(batch) * (1 - momentum)\n",
    "# Test mode:\n",
    "# (batch - moving_mean) / sqrt(moving_var + epsilon) * gamma + beta\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "    def __init__(self, momentum=0.99, epsilon=0.001, beta_init=None, gamma_init=None,\n",
    "                 moving_mean_init=None, moving_var_init=None,\n",
    "                 mode='train', input_channels=2):\n",
    "      # mode: 'train', 'test'\n",
    "      # Параметры gamma, beta, mean, var - все имеют размерность по количеству карт input_channels   \n",
    "      self.name = 'BatchNorm'\n",
    "      self.momentum = momentum\n",
    "      self.epsilon = epsilon\n",
    "      self.beta = beta_init\n",
    "      self.gamma = gamma_init\n",
    "      self.moving_mean = moving_mean_init\n",
    "      self.moving_var = moving_var_init\n",
    "      self.mode = mode\n",
    "      self.input_channels = input_channels\n",
    "    \n",
    "    def forward(self, input_data):   \n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # 1) Нужно заполнить Numpy-тензор out (той же размерности, что и вход)\n",
    "      # 2) Нужно обновить moving_mean и moving_var в режиме 'train'\n",
    "      # out = np.empty([])\n",
    "\n",
    "      shape = input_data.shape\n",
    "      out = []\n",
    "      mean = []\n",
    "      var = []\n",
    "    \n",
    "      if self.mode == 'train':\n",
    "          mean = [np.mean(input_data[:, i]) for i in range(shape[1])]\n",
    "          var = [np.var(input_data[:, i]) for i in range(shape[1])]\n",
    "          self.moving_mean = np.array([self.moving_mean[i] * self.momentum + mean[i] * (1 - self.momentum) for i in range(self.input_channels)])\n",
    "          self.moving_var = np.array([self.moving_var[i] * self.momentum + var[i] * (1 - self.momentum) for i in range(self.input_channels)])\n",
    "            \n",
    "      elif self.mode == 'test':\n",
    "          mean = self.moving_mean\n",
    "          var = self.moving_var\n",
    "            \n",
    "      for batch in range(shape[0]):\n",
    "          batch_arr = []\n",
    "          for channel in range(shape[1]):\n",
    "              result = self.gamma[channel] * (input_data[batch, channel] - mean[channel]) / np.sqrt(var[channel] + self.epsilon) + self.beta[channel]\n",
    "              batch_arr.append(result)\n",
    "          out.append(batch_arr)\n",
    "          \n",
    "      out = np.array(out)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NhZ6TK-RYfm-"
   },
   "outputs": [],
   "source": [
    "def test_BatchNormLayer():\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 4\n",
    "  W = 4\n",
    "  beta_init = 0 * np.ones(C)\n",
    "  gamma_init = 1 * np.ones(C)\n",
    "  moving_mean_init = 0 * np.ones(C)\n",
    "  moving_var_init= 1 * np.ones(C)\n",
    "  momentum = 0.99\n",
    "  epsilon = 0.001\n",
    "  mode = 'train'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=True)\n",
    "  y_keras = y(x, training=True).numpy()\n",
    "  y.set_weights([gamma_init, beta_init, moving_mean_init, moving_var_init])\n",
    "  y_keras = y(x, training=True).numpy()\n",
    "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
    "                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\n",
    "                 mode=mode, input_channels=C)\n",
    "  y_out = y_out_layer.forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 1')\n",
    "  compare_tensors_array(y.get_weights(), \n",
    "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
    "                        tol=0.00001, test_name='Test BatchNorm 1.1')\n",
    "\n",
    "  B = 2 \n",
    "  C = 2 \n",
    "  H = 4 \n",
    "  W = 4 \n",
    "  beta_init = 1 * np.ones(C)\n",
    "  gamma_init = 0 * np.ones(C)\n",
    "  moving_mean = 0 * np.ones(C)\n",
    "  moving_var = 1 * np.ones(C)\n",
    "  momentum = 0.99\n",
    "  epsilon = 0.001\n",
    "  mode = 'test'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=False)\n",
    "  y_keras = y(x, training=False).numpy()\n",
    "  y.set_weights([gamma_init, beta_init, moving_mean, moving_var])\n",
    "  y_keras = y(x, training=False).numpy()\n",
    "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
    "                 moving_mean_init=moving_mean, moving_var_init=moving_var,\n",
    "                 mode=mode, input_channels=C)\n",
    "  y_out = y_out_layer.forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 2')  \n",
    "  compare_tensors_array(y.get_weights(), \n",
    "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
    "                        tol=0.00001, test_name='Test BatchNorm 2.1')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kZ2F0Xg1Yf94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BatchNorm 1 Passed!\n",
      "Test BatchNorm 1.1 subtest 0 Passed!\n",
      "Test BatchNorm 1.1 subtest 1 Passed!\n",
      "Test BatchNorm 1.1 subtest 2 Passed!\n",
      "Test BatchNorm 1.1 subtest 3 Passed!\n",
      "Test BatchNorm 1.1 Passed!\n",
      "Test BatchNorm 2 Passed!\n",
      "Test BatchNorm 2.1 subtest 0 Passed!\n",
      "Test BatchNorm 2.1 subtest 1 Passed!\n",
      "Test BatchNorm 2.1 subtest 2 Passed!\n",
      "Test BatchNorm 2.1 subtest 3 Passed!\n",
      "Test BatchNorm 2.1 Passed!\n"
     ]
    }
   ],
   "source": [
    "test_BatchNormLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJKt_4mCyV4r"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f_m9DaTaHio"
   },
   "source": [
    "* (1 балл) Реализация **полносвязного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1Ln22ERp8mC5"
   },
   "outputs": [],
   "source": [
    "class DenseLayer(Layer):\n",
    "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
    "      self.name = 'Dense'\n",
    "      self.input_dim = input_dim\n",
    "      self.output_dim = output_dim\n",
    "      self.W = W_init\n",
    "      self.b = b_init\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "      # На входе - двухмерный тензор вида [batch, input_channels]\n",
    "      # Работаем по второй размерности, по первой размерности НЕ преобразуем\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([]) #\n",
    "      assert input_data.shape[-1] == self.W.shape[0] == self.input_dim\n",
    "      out = input_data @ self.W + self.b\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ln9JIKL8YhZF"
   },
   "outputs": [],
   "source": [
    "def test_DenseLayer():\n",
    "  B = 1\n",
    "  C_IN = 10\n",
    "  C_OUT = 5\n",
    "  x = np.random.randn(B, C_IN)\n",
    "  W_init = np.random.randn(C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Dense(C_OUT, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([W_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 1')\n",
    "  B = 2\n",
    "  C_IN = 5\n",
    "  C_OUT = 10\n",
    "  x = np.random.randn(B, C_IN)\n",
    "  W_init = np.random.randn(C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Dense(C_OUT, use_bias=True, input_shape=(C_IN,))\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([W_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  print(y_keras)\n",
    "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "  print(y_out)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NA_KNjZYhec"
   },
   "outputs": [],
   "source": [
    "test_DenseLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "966wyQwryXun"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6A8OLysaS3Q"
   },
   "source": [
    "* (2 балла) Реализация **сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "quhEATTW9jyK"
   },
   "outputs": [],
   "source": [
    "class Conv2DLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding='same', stride=1, K_init=None, b_init=None):\n",
    "      # padding: 'same' или 'valid'\n",
    "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "      # Работаем с единообразным сдвигом, поэтому stride - одно число\n",
    "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "      self.name = 'Conv2D'\n",
    "      self.kernel_size = kernel_size\n",
    "      self.input_channels = input_channels\n",
    "      self.output_channels = output_channels\n",
    "      self.kernel = K_init\n",
    "      self.bias = b_init\n",
    "      self.padding = padding\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "#       assert self.kernel_size[-1] == self.output_channels, self.kernel_size[-2] == self.input_channels\n",
    "#       assert input_data[1] == self.input_channels\n",
    "      \n",
    "      return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "aUA1PbOBYiH3"
   },
   "outputs": [],
   "source": [
    "def test_Conv2DLayer():\n",
    "  B = 1\n",
    "  C_IN = 1\n",
    "  C_OUT = 1\n",
    "  H = 10\n",
    "  W = 10\n",
    "  K = 3\n",
    "  S = 1\n",
    "  padding = 'same'\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
    "    dilation_rate=1, groups=1, activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([K_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  print(x)\n",
    "  print(K_init)\n",
    "  print(b_init)\n",
    "  print(y_keras)\n",
    "\n",
    "#   y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "#                  padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "#   print(y_out)\n",
    "#   compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\n",
    "\n",
    "#   B = 2\n",
    "#   C_IN = 3\n",
    "#   C_OUT = 5\n",
    "#   H = 9\n",
    "#   W = 9\n",
    "#   K = 3\n",
    "#   S = 2\n",
    "#   padding = 'valid'\n",
    "#   x = np.random.randn(B, C_IN, H, W)\n",
    "#   K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "#   b_init = np.random.randn(C_OUT)\n",
    "#   y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
    "#     dilation_rate=1, groups=1, activation=None, use_bias=True, input_shape=(C_IN, H, W))\n",
    "#   y_keras = y(x).numpy()\n",
    "#   y.set_weights([K_init, b_init])\n",
    "#   y_keras = y(x).numpy()\n",
    "#   y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "#                  padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "#   print(x)\n",
    "#   print(K_init)\n",
    "#   print (b_init)\n",
    "#   print(y_keras)\n",
    "#   print(y_out)\n",
    "#   compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "cZI5iUu4YiOD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.33810245  0.50561549 -2.08248016  0.23325591  0.53277484\n",
      "     1.97011148 -0.37944922 -1.34314863  2.46978494  1.11003021]\n",
      "   [ 0.27297025 -0.32563047 -0.07173462  0.46644386 -0.56924185\n",
      "    -0.99514498 -1.31138017 -0.65533014  0.80680934 -2.07072258]\n",
      "   [ 0.11522915  0.49470898 -0.19826275  2.38524529  0.69625707\n",
      "     0.59525819  0.01456653 -0.76295249  0.22539998  0.9780864 ]\n",
      "   [-1.19762031 -0.12016672 -0.39350596 -0.65021846 -0.04573665\n",
      "    -0.50577363  1.89160395 -2.72709064  1.01974559  0.94212133]\n",
      "   [ 0.07368161  0.14014638  0.33364052  0.92671546  0.6037298\n",
      "     1.29983793  0.48106357  2.32106652  1.69256248 -1.93717853]\n",
      "   [ 0.67978298  0.25327346 -2.66800411 -0.94412671 -0.26273395\n",
      "    -0.20955409 -0.75756119 -0.850852    1.33903918 -2.36113146]\n",
      "   [-0.14234271  0.63042205  0.70899265 -0.77700189 -0.5914539\n",
      "     1.00591701  1.95847309 -0.70882734 -0.45067135  0.94307293]\n",
      "   [ 1.05134908 -1.07586943  0.74146745 -0.90691587 -2.87408321\n",
      "    -2.37739167 -2.06621606 -2.53410406  0.35270826  0.07682136]\n",
      "   [ 0.04071941  0.22033619  0.3929327  -0.71014051  1.62909503\n",
      "     1.69380782 -1.28294949  1.69189032  1.08384622 -1.7884204 ]\n",
      "   [ 1.17208356  1.55891436 -0.49740564  0.2131538   0.10213847\n",
      "    -0.80960307 -0.01795926 -0.16208181 -0.26619135  0.6435263 ]]]]\n",
      "[[[[ 0.17140324]]\n",
      "\n",
      "  [[-0.27669533]]\n",
      "\n",
      "  [[ 0.0273877 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.31955287]]\n",
      "\n",
      "  [[-0.39142543]]\n",
      "\n",
      "  [[ 0.82467543]]]\n",
      "\n",
      "\n",
      " [[[-0.09708627]]\n",
      "\n",
      "  [[-0.3703142 ]]\n",
      "\n",
      "  [[-0.09663798]]]]\n",
      "[-0.11772539]\n",
      "[[[[ 0.09728487 -1.8239486   1.0644441  -0.5458798   1.634655\n",
      "    -0.48103887  0.19826119  2.6155608  -0.6332934   0.9254954 ]\n",
      "   [-0.66329473 -0.27640384  0.65511197 -2.1308858  -1.1669395\n",
      "    -1.7451969  -0.04641975  1.0186696  -3.3377316   0.6827328 ]\n",
      "   [ 0.6158059  -0.10432435  2.282051   -0.41407996  1.2019917\n",
      "     0.03458016 -0.7759087   1.0777844  -0.23933886 -0.16518123]\n",
      "   [ 0.1927919  -0.9917637  -0.56005055 -1.1354884  -0.9313655\n",
      "     0.99417436 -3.7202744   1.5451345  -1.4426557   0.16040947]\n",
      "   [ 0.02088474  0.04134661  1.6858282   0.8692834   1.1105987\n",
      "     0.32336026  1.7217948   1.8892481  -2.5449502   1.839864  ]\n",
      "   [-0.1997016  -2.5050352  -0.06264672 -0.7240465  -0.26475456\n",
      "    -1.4917489  -1.1909914   0.6799945  -2.8398888   1.7550153 ]\n",
      "   [-0.00863108  0.37276536 -0.16126686  0.2635544   1.9822874\n",
      "     2.265929    0.2438141   1.6610882   0.13687943  0.1892571 ]\n",
      "   [-1.3962137   0.9478946  -1.7073355  -1.5082711  -1.8831167\n",
      "    -2.7970269  -2.4002197   0.41755193 -1.3659735   0.18377422]\n",
      "   [-0.8570166  -0.01172983 -1.1889137   1.8880806   1.0089264\n",
      "    -0.9179357   2.516707    0.14804436 -1.9539096   0.75538987]\n",
      "   [ 0.7038573  -0.8068047   0.66050464  0.03258415 -1.2833447\n",
      "    -0.00757167  0.18857576 -0.93789864  0.40649492  0.22594218]]]]\n"
     ]
    }
   ],
   "source": [
    "test_Conv2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91-bDvSvyY2e"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hPqOr5zad6H"
   },
   "source": [
    "* (2 балла) Реализация **транспонированного сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97D7QOwm-ER1"
   },
   "outputs": [],
   "source": [
    "class Conv2DTrLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding=0, stride=1, K_init=None, b_init=None):      \n",
    "      # padding: число (сколько отрезать от модифицированной входной карты)\n",
    "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "      # stride - одно число (коэффициент расширения)\n",
    "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "      self.name = 'Conv2DTr'\n",
    "      self.kernel_size = kernel_size\n",
    "      self.input_channels = input_channels\n",
    "      self.output_channels = output_channels\n",
    "      self.kernel = K_init\n",
    "      self.bias = b_init\n",
    "      self.padding = padding\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueU3lS9-Yi8t"
   },
   "outputs": [],
   "source": [
    "def adjust_kernel(K):\n",
    "  K_new = K.copy()[::-1, ::-1, :, :]\n",
    "  K_new = np.transpose(K_new, (0, 1, 3, 2))\n",
    "  return K_new\n",
    "\n",
    "def test_Conv2DTrLayer():\n",
    "  B = 1\n",
    "  C_IN = 1\n",
    "  C_OUT = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 0\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
    "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
    "                    activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([adjust_kernel(K_init), b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 1')\n",
    "  B = 4\n",
    "  C_IN = 2\n",
    "  C_OUT = 3\n",
    "  H = 3\n",
    "  W = 3\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 0\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
    "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
    "                    activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([adjust_kernel(K_init), b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rW2REQR3-6dd"
   },
   "outputs": [],
   "source": [
    "test_Conv2DTrLayer()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Practice01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
